{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61022953-1bfc-4967-89d8-1e7249c66e9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T19:03:27.462293Z",
     "iopub.status.busy": "2025-01-28T19:03:27.461899Z",
     "iopub.status.idle": "2025-01-28T19:03:34.327193Z",
     "shell.execute_reply": "2025-01-28T19:03:34.326189Z",
     "shell.execute_reply.started": "2025-01-28T19:03:27.462268Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "159c21b5-e44d-42a4-8885-18c46cb23b98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T19:06:17.139071Z",
     "iopub.status.busy": "2025-01-28T19:06:17.138366Z",
     "iopub.status.idle": "2025-01-28T19:06:17.340537Z",
     "shell.execute_reply": "2025-01-28T19:06:17.339273Z",
     "shell.execute_reply.started": "2025-01-28T19:06:17.139031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Holographic Goose</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>973.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kaggle Tiers</td>\n",
       "      <td>906.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kerneler</td>\n",
       "      <td>423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kerneler Dark Mode</td>\n",
       "      <td>491.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230125</th>\n",
       "      <td>230125</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Premium Sticker Mart</td>\n",
       "      <td>Holographic Goose</td>\n",
       "      <td>466.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230126</th>\n",
       "      <td>230126</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Premium Sticker Mart</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>2907.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230127</th>\n",
       "      <td>230127</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Premium Sticker Mart</td>\n",
       "      <td>Kaggle Tiers</td>\n",
       "      <td>2299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230128</th>\n",
       "      <td>230128</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Premium Sticker Mart</td>\n",
       "      <td>Kerneler</td>\n",
       "      <td>1242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230129</th>\n",
       "      <td>230129</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Premium Sticker Mart</td>\n",
       "      <td>Kerneler Dark Mode</td>\n",
       "      <td>1622.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230130 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id        date    country                 store  \\\n",
       "0            0  2010-01-01     Canada     Discount Stickers   \n",
       "1            1  2010-01-01     Canada     Discount Stickers   \n",
       "2            2  2010-01-01     Canada     Discount Stickers   \n",
       "3            3  2010-01-01     Canada     Discount Stickers   \n",
       "4            4  2010-01-01     Canada     Discount Stickers   \n",
       "...        ...         ...        ...                   ...   \n",
       "230125  230125  2016-12-31  Singapore  Premium Sticker Mart   \n",
       "230126  230126  2016-12-31  Singapore  Premium Sticker Mart   \n",
       "230127  230127  2016-12-31  Singapore  Premium Sticker Mart   \n",
       "230128  230128  2016-12-31  Singapore  Premium Sticker Mart   \n",
       "230129  230129  2016-12-31  Singapore  Premium Sticker Mart   \n",
       "\n",
       "                   product  num_sold  \n",
       "0        Holographic Goose       NaN  \n",
       "1                   Kaggle     973.0  \n",
       "2             Kaggle Tiers     906.0  \n",
       "3                 Kerneler     423.0  \n",
       "4       Kerneler Dark Mode     491.0  \n",
       "...                    ...       ...  \n",
       "230125   Holographic Goose     466.0  \n",
       "230126              Kaggle    2907.0  \n",
       "230127        Kaggle Tiers    2299.0  \n",
       "230128            Kerneler    1242.0  \n",
       "230129  Kerneler Dark Mode    1622.0  \n",
       "\n",
       "[230130 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv', sep=',')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3e73ef3-2573-4cf0-8e06-b0f385510161",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T19:36:51.498027Z",
     "iopub.status.busy": "2025-01-28T19:36:51.497657Z",
     "iopub.status.idle": "2025-01-28T19:36:53.331771Z",
     "shell.execute_reply": "2025-01-28T19:36:53.330778Z",
     "shell.execute_reply.started": "2025-01-28T19:36:51.497995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221229, 30, 19)\n",
      "(221229,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Wczytaj dane\n",
    "data = pd.read_csv('train.csv')\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "data = data.dropna()\n",
    "\n",
    "# Rozbij daty na cechy\n",
    "data['year'] = data['date'].dt.year\n",
    "data['month'] = data['date'].dt.month\n",
    "data['day'] = data['date'].dt.day\n",
    "data['weekday'] = data['date'].dt.weekday\n",
    "\n",
    "# One-hot encoding dla kategorii\n",
    "encoder = OneHotEncoder()\n",
    "categories = encoder.fit_transform(data[['country', 'store', 'product']]).toarray()\n",
    "\n",
    "# Połącz cechy\n",
    "features = np.hstack([\n",
    "    data[['year', 'month', 'day', 'weekday']].values,\n",
    "    categories,\n",
    "    data['num_sold'].values.reshape(-1, 1)\n",
    "])\n",
    "\n",
    "# Tworzenie sekwencji\n",
    "def create_sequences(data, sequence_length):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        sequences.append(data[i:i + sequence_length])\n",
    "    return np.array(sequences)\n",
    "\n",
    "sequence_length = 30\n",
    "X = create_sequences(features, sequence_length)\n",
    "y = data['num_sold'][sequence_length:].values\n",
    "\n",
    "print(X.shape)  # [num_samples, sequence_length, num_features]\n",
    "print(y.shape)  # [num_samples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5defb32-ed77-4cd0-b80e-f7c3715e2deb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T19:37:41.277253Z",
     "iopub.status.busy": "2025-01-28T19:37:41.276643Z",
     "iopub.status.idle": "2025-01-28T19:37:41.285195Z",
     "shell.execute_reply": "2025-01-28T19:37:41.283663Z",
     "shell.execute_reply.started": "2025-01-28T19:37:41.277205Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    \"\"\"Oblicza MAPE. Dodaje eps, by unikać dzielenia przez zero.\"\"\"\n",
    "    eps = 1e-10  # Mała wartość zapobiegająca dzieleniu przez zero\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / (y_true + eps))) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87d9d63c-c290-4af7-aa35-6a4de43901cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T19:38:12.122579Z",
     "iopub.status.busy": "2025-01-28T19:38:12.122119Z",
     "iopub.status.idle": "2025-01-28T19:48:37.548701Z",
     "shell.execute_reply": "2025-01-28T19:48:37.547035Z",
     "shell.execute_reply.started": "2025-01-28T19:38:12.122544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1347450.625, Train MAPE: 236.03%\n",
      "Epoch 2, Loss: 421107.03125, Train MAPE: 100.21%\n",
      "Epoch 3, Loss: 365866.59375, Train MAPE: 110.76%\n",
      "Epoch 4, Loss: 824197.5, Train MAPE: 140.93%\n",
      "Epoch 5, Loss: 800457.25, Train MAPE: 139.04%\n",
      "Epoch 6, Loss: 220519.984375, Train MAPE: 151.12%\n",
      "Epoch 7, Loss: 290839.96875, Train MAPE: 154.33%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Ocena modelu na zbiorze treningowym (lub walidacyjnym)\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m train_mape \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train MAPE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_mape\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 31\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# Wyłączenie gradientów dla szybszej ewaluacji\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m---> 31\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     32\u001b[0m         true_values\u001b[38;5;241m.\u001b[39mextend(y_batch\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     33\u001b[0m         predictions\u001b[38;5;241m.\u001b[39mextend(y_pred\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 21\u001b[0m, in \u001b[0;36mSalesLSTM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 21\u001b[0m     _, (hn, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# hn to ostatni ukryty stan\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(hn[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:878\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    875\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 878\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    882\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Dane wejściowe (X) i etykiety (y)\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Tworzenie datasetu i loadera\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Definicja modelu LSTM\n",
    "class SalesLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(SalesLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hn, _) = self.lstm(x)  # hn to ostatni ukryty stan\n",
    "        return self.fc(hn[-1])     # Przekształcenie do wymiaru wyjściowego\n",
    "\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()  # Ustawienie modelu w tryb ewaluacji\n",
    "    true_values = []\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():  # Wyłączenie gradientów dla szybszej ewaluacji\n",
    "        for X_batch, y_batch in loader:\n",
    "            y_pred = model(X_batch).squeeze()\n",
    "            true_values.extend(y_batch.numpy())\n",
    "            predictions.extend(y_pred.numpy())\n",
    "    \n",
    "    # Obliczenie MAPE\n",
    "    mape = mean_absolute_percentage_error(true_values, predictions)\n",
    "    return mape\n",
    "\n",
    "# Model\n",
    "input_size = 19  # Liczba cech\n",
    "hidden_size = 50  # Liczba neuronów w warstwie ukrytej\n",
    "num_layers = 2    # Liczba warstw LSTM\n",
    "output_size = 1   # Jedna wartość przewidywana (num_sold)\n",
    "model = SalesLSTM(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "# Loss i optymalizator\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Trenowanie modelu\n",
    "for epoch in range(10):  # Liczba epok\n",
    "    model.train()  # Ustawienie modelu w tryb treningowy\n",
    "    for X_batch, y_batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_batch).squeeze()\n",
    "        loss = criterion(predictions, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Ocena modelu na zbiorze treningowym (lub walidacyjnym)\n",
    "    train_mape = evaluate_model(model, loader)\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}, Train MAPE: {train_mape:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb43c7ff-a33e-4b29-9fe5-24a707367672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T19:48:46.028046Z",
     "iopub.status.busy": "2025-01-28T19:48:46.027596Z",
     "iopub.status.idle": "2025-01-28T19:48:46.038427Z",
     "shell.execute_reply": "2025-01-28T19:48:46.036550Z",
     "shell.execute_reply.started": "2025-01-28T19:48:46.028010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 681.,  627.,  340., ..., 2299., 1242., 1622.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef9bf75d-816d-48b4-8975-2a4ac6ee40b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T19:53:05.089251Z",
     "iopub.status.busy": "2025-01-28T19:53:05.088806Z",
     "iopub.status.idle": "2025-01-28T20:00:23.269246Z",
     "shell.execute_reply": "2025-01-28T20:00:23.268327Z",
     "shell.execute_reply.started": "2025-01-28T19:53:05.089215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1074921.75, Train MAPE: 235.48%\n",
      "Epoch 2, Loss: 550978.25, Train MAPE: 408.76%\n",
      "Epoch 3, Loss: 777644.875, Train MAPE: 583.14%\n",
      "Epoch 4, Loss: 309161.65625, Train MAPE: 744.21%\n",
      "Epoch 5, Loss: 413642.875, Train MAPE: 858.66%\n",
      "Epoch 6, Loss: 433414.8125, Train MAPE: 899.96%\n",
      "Epoch 7, Loss: 368106.90625, Train MAPE: 906.34%\n",
      "Epoch 8, Loss: 891496.375, Train MAPE: 906.73%\n",
      "Epoch 9, Loss: 487629.875, Train MAPE: 908.21%\n",
      "Epoch 10, Loss: 513807.03125, Train MAPE: 907.10%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)\n",
    "\n",
    "y_scaled = y\n",
    "# 2. Tworzenie tensora PyTorch\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_scaled, dtype=torch.float32)\n",
    "\n",
    "# 3. Tworzenie datasetu i loadera\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 4. Definicja modelu LSTM\n",
    "class SalesLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(SalesLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hn, _) = self.lstm(x)  # hn to ostatni ukryty stan\n",
    "        return self.fc(hn[-1])     # Przekształcenie do wymiaru wyjściowego\n",
    "\n",
    "# 5. Inicjalizacja modelu\n",
    "input_size = 19  # Liczba cech\n",
    "hidden_size = 50  # Liczba neuronów w warstwie ukrytej\n",
    "num_layers = 2    # Liczba warstw LSTM\n",
    "output_size = 1   # Jedna wartość przewidywana (num_sold)\n",
    "model = SalesLSTM(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "# 6. Loss i optymalizator\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 7. Funkcja do obliczania MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    eps = 1e-10  # Mała wartość zapobiegająca dzieleniu przez zero\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / (y_true + eps))) * 100\n",
    "\n",
    "# 8. Funkcja ewaluacji modelu i obliczania MAPE\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()  # Ustawienie modelu w tryb ewaluacji\n",
    "    true_values = []\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():  # Wyłączenie gradientów dla szybszej ewaluacji\n",
    "        for X_batch, y_batch in loader:\n",
    "            y_pred = model(X_batch).squeeze()\n",
    "            true_values.extend(y_batch.numpy())\n",
    "            predictions.extend(y_pred.numpy())\n",
    "    \n",
    "    # Obliczenie MAPE\n",
    "    mape = mean_absolute_percentage_error(true_values, predictions)\n",
    "    return mape\n",
    "\n",
    "# 9. Trenowanie modelu\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):  # Liczba epok\n",
    "    model.train()  # Ustawienie modelu w tryb treningowy\n",
    "    for X_batch, y_batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_batch).squeeze()\n",
    "        loss = criterion(predictions, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Ocena modelu na zbiorze treningowym (lub walidacyjnym)\n",
    "    train_mape = evaluate_model(model, loader)\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}, Train MAPE: {train_mape:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "084ce441-601f-44e5-a74a-10fab28337aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T19:52:31.509897Z",
     "iopub.status.busy": "2025-01-28T19:52:31.509059Z",
     "iopub.status.idle": "2025-01-28T19:52:31.544100Z",
     "shell.execute_reply": "2025-01-28T19:52:31.540937Z",
     "shell.execute_reply.started": "2025-01-28T19:52:31.509834Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43my_scaled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "y_scaled.shape()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
